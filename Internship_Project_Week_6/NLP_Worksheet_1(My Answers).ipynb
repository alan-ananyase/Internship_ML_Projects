{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What will be the output of the following lines of code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', '#', 'food', '#', 'pasta']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "doc = \"I love #food #pasta\"\n",
    "print( word_tokenize(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What will be the output of the following lines of code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', '#food', '#pasta']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknz = TweetTokenizer()\n",
    "doc = \"I love #food #pasta\"\n",
    "print( tknz.tokenize(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Consider the following two documents we create a bow representation using Count Vectorizer of NLTK library. What will the shape of the resultant data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "Doc1 = \"HE love python\"\n",
    "Doc2 = \"HE love eating healthy\"\n",
    "vectrz = CountVectorizer()\n",
    "Bow_array = vectrz.fit_transform([Doc1, Doc2])\n",
    "print(Bow_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For questions Q12-Q15, Consider the following Documents and answer the Questions\n",
    "\n",
    "- Document1: \"Vapour, Bangalore has a really great terrace seating and an awesome view of the Bangalore skyline\"\n",
    "- Document2: \"The beer at Vapour, Bangalore was amazing. My favorites are the wheat beer and the ale beer.\"\n",
    "- Document3: \"Vapour, Bangalore has the best view in Bangalore.\"\n",
    "\n",
    "#### Please remove the stopwords from the above documents before answering the below questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "tfid = TfidfVectorizer(smooth_idf=False)\n",
    "text=[\"Vapour, Bangalore has a really great terrace seating and an awesome view of the Bangalore skyline\",\n",
    "      \"The beer at Vapour, Bangalore was amazing. My favorites are the wheat beer and the ale beer.\",\n",
    "      \"Vapour, Bangalore has the best view in Bangalore.\"]\n",
    "\n",
    "filtered_sentence = [w.lower() for w in text if not w.lower() in stop_words]\n",
    "\n",
    "text_vector=tfid.fit_transform(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ale</th>\n",
       "      <th>amazing</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>at</th>\n",
       "      <th>awesome</th>\n",
       "      <th>bangalore</th>\n",
       "      <th>beer</th>\n",
       "      <th>best</th>\n",
       "      <th>...</th>\n",
       "      <th>of</th>\n",
       "      <th>really</th>\n",
       "      <th>seating</th>\n",
       "      <th>skyline</th>\n",
       "      <th>terrace</th>\n",
       "      <th>the</th>\n",
       "      <th>vapour</th>\n",
       "      <th>view</th>\n",
       "      <th>was</th>\n",
       "      <th>wheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305596</td>\n",
       "      <td>0.204661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305596</td>\n",
       "      <td>0.291237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305596</td>\n",
       "      <td>0.305596</td>\n",
       "      <td>0.305596</td>\n",
       "      <td>0.305596</td>\n",
       "      <td>0.305596</td>\n",
       "      <td>0.145618</td>\n",
       "      <td>0.145618</td>\n",
       "      <td>0.204661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.223908</td>\n",
       "      <td>0.223908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149954</td>\n",
       "      <td>0.223908</td>\n",
       "      <td>0.223908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106694</td>\n",
       "      <td>0.671725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320081</td>\n",
       "      <td>0.106694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223908</td>\n",
       "      <td>0.223908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230885</td>\n",
       "      <td>0.230885</td>\n",
       "      <td>0.324500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ale   amazing        an       and       are        at   awesome  \\\n",
       "0  0.000000  0.000000  0.305596  0.204661  0.000000  0.000000  0.305596   \n",
       "1  0.223908  0.223908  0.000000  0.149954  0.223908  0.223908  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "   bangalore      beer      best  ...        of    really   seating   skyline  \\\n",
       "0   0.291237  0.000000  0.000000  ...  0.305596  0.305596  0.305596  0.305596   \n",
       "1   0.106694  0.671725  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.461769  0.000000  0.484537  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "    terrace       the    vapour      view       was     wheat  \n",
       "0  0.305596  0.145618  0.145618  0.204661  0.000000  0.000000  \n",
       "1  0.000000  0.320081  0.106694  0.000000  0.223908  0.223908  \n",
       "2  0.000000  0.230885  0.230885  0.324500  0.000000  0.000000  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(text_vector.todense(), columns=tfid.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. What will be the tf-idf score of word “Bangalore” in Document 1?<br>\n",
    "**0.2**\n",
    "13. What will be the tf-idf score of the word “beer” in document 2?<br>\n",
    "**0.6**\n",
    "14. Which of the following statements are true regarding the above documents?<br>\n",
    "A) _The tf-idf score of “vapour” is greater than tf-idf score of “Bangalore” in document 1_ <br>\n",
    "B) _The tf-idf score of “vapour” is less than tf-idf score of “Bangalore” in document 1_ <br>\n",
    "C) _tf-idf of both “vapour” and “Bangalore” are equal to zero_ <br>\n",
    "D) _tf-idf of both “vapour” and “Bangalore” are equal and non-zero_ <br>\n",
    "**The tf-idf score of “vapour” is less than tf-idf score of “Bangalore” in document 1** <br>\n",
    "15. Which of the following are advantages of using tf-idf model over BOW model?<br>\n",
    "A) _The bow model gives equal importance to all the words while tf-idf model gives more importance to those words in a document which occurs exclusively only I this document .4_ <br>\n",
    "B) _The tf-idf model gives equal importance to all the words in a document regardless of whether that word occurs in other documents or not, while BOW model takes in to consideration whether a word occurs in other documents also._ <br>\n",
    "C) _Both models work on same concept but have different names_ <br>\n",
    "D) _None of the above._ <br>\n",
    "**The bow model gives equal importance to all the words while tf-idf model gives more importance to those words in a document which occurs exclusively only I this document .4**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
